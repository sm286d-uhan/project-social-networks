{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4 class='prehead'>SM286D &middot; Introduction to Applied Mathematics with Python &middot; Spring 2020 &middot; Foraker/Traves/Uhan</h4>\n",
    "\n",
    "<h3 class='lesson'>Project 5.</h3>\n",
    "\n",
    "<h1 class='lesson_title'>Social Network Analysis</h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Mathematical goals.__  Graphs, measures of centrality, approximation of eigenvectors using the power method, PageRank algorithm.\n",
    "\n",
    "__Programming goals.__ Loops, dictionaries, NetworkX, navigating documentation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Background"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Edward Snowden is a computer professional who worked as a contractor for the NSA. In 2013, he provided a massive amount of classified information to journalists who later published articles in *The Guardian* and *The Washington Post*. The information leaked by Snowdon revealed the existence of many mass surveillance programs operated by the NSA and our allies. Charged with violating the Espionage Act of 1917 and the theft of government property, Snowden sought asylum in Russia, where he continues to live today. \n",
    "\n",
    "Snowden's actions remain deeply controversial; many see him as a traitor, while others see him as a patriot and a whistleblower. Whatever your perspective, Snowden has \"fueled debates over mass surveillance, government secrecy and the balance between national security and information privacy.\" (Wikipedia page on Edward Snowden, retrieved 08 OCT 2016) A documentary, _Citizenfour_, about Snowden and these issues won the 2015 Academy Award for Best Documentary Feature; Figure 1 is pulled from a screenshot from the film. In 2016 Oliver Stone released another biopic about Snowden.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"img/Edward_Snowden-2.jpg\" alt=\"Drawing\" style=\"width: 220px;\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center> Figure 1. Edward Snowden (Laura Poitras of Praxis Films) </center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One program run by the NSA involved getting meta-data on phone calls between individuals in the United States. This data didn't contain details of conversations but did help government agencies build a graph describing the network of relationships among persons of interest. A graph consists of a collection of vertices joined by edges connecting one vertex to another. For instance, each vertex might correspond to one of the 9/11 hijackers or their contacts, and edges between vertices might represent known associations between the terrorists and their accomplices. [Valdis Krebs](http://www.orgnet.com/hijackers.html) built such a graph, pictured in Figure 2. His paper, _Mapping Networks of Terrorist Cells_, describes some of the connections between the terrorists. His goal in the paper is to use the graph to identify the key members of the terrorist network. This kind of Social Network Analysis has been used to study a wide range of networks, including: economic networks, co-authorship networks in academia, networks of lobbyists, online social networks (e.g. Twitter or Facebook), and political networks. See http://www.orgnet.com/cases.html for details of these applications."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"img/hijackers_graph_with_0_based_labels2.jpg\" alt=\"Drawing\" style=\"width: 600px;\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center> Figure 2. A graph $G$ presenting the social network of the 9/11 hijackers (Krebs, http://www.orgnet.com/hijackers.html; the numerical labels are new). </center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Following Krebs, our goal in this assignment is to use several measures of centrality to identify the key members of the 9/11 terrorist network. First we need to associate a vertex with each conspirator. The numbered list of vertices and their associated conspirators is presented in the dictionary `names` in the code provided below. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import numpy  \n",
    "import numpy as np\n",
    "\n",
    "# Define a dictionary that maps numbers to names\n",
    "# a * next to a name indicates that the person is suspected of using a false ID\n",
    "names = {\n",
    "    0: 'Mohamed Atta',\n",
    "    1: 'Nawaf Alhazmi',\n",
    "    2: 'Hani Hanjour',\n",
    "    3: 'Marwan Al-Shehhi',\n",
    "    4: 'Ziad Jarrah',\n",
    "    5: 'Mustafa al-Hisawi',\n",
    "    6: 'Salem Alhazmi*',\n",
    "    7: 'Lotfi Raissi',\n",
    "    8: 'Saeed Alghamdi*',\n",
    "    9: 'Abdul Aziz Al-Omari*',\n",
    "    10: 'Hamza Alghamdi',\n",
    "    11: 'Ramzi Bin al-Shibh',\n",
    "    12: 'Said Bahaji',\n",
    "    13: 'Ahmed Al Haznawi',\n",
    "    14: 'Zakariya Essabar',\n",
    "    15: 'Agus Budiman',\n",
    "    16: 'Khalid Al-Mihdhar',\n",
    "    17: 'Ahmed Alnami',\n",
    "    18: 'Mounir El Motassadeq',\n",
    "    19: 'Fayez Ahmed',\n",
    "    20: 'Mamoun Darkazanli',\n",
    "    21: 'Zacarias Moussaoui',\n",
    "    22: 'Ahmed Khalil Ibrahim Samir Al-Ani',\n",
    "    23: 'Abdussattar Shaikh',\n",
    "    24: 'Osama Awadallah',\n",
    "    25: 'Mohamed Abdi',\n",
    "    26: 'Rayed Mohammed Abdullah',\n",
    "    27: 'Bandar Alhazmi',\n",
    "    28: 'Faisal Al Salmi',\n",
    "    29: 'Mohand Alshehri*',\n",
    "    30: 'Majed Moqed',\n",
    "    31: 'Waleed Alshehri',\n",
    "    32: 'Nabil al-Marabh',\n",
    "    33: 'Raed Hijazi',\n",
    "    34: 'Ahmed Alghamdi',\n",
    "    35: 'Satam Suqami',\n",
    "    36: 'Wail Alshehri'\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The code below produces the adjacency matrix of the graph $G$ in Figure 2, a $37\\times 37$ matrix $A$ with \n",
    "\n",
    "\\begin{equation*}\n",
    "A_{ij} = \\begin{cases}\n",
    "1 & \\text{if vertices $i$ and $j$ are connected by an edge},\\\\\n",
    "0 & \\text{otherwise}.\n",
    "\\end{cases}\n",
    "\\end{equation*}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize matrix of zeros\n",
    "A = np.zeros([37,37])\n",
    "\n",
    "# Change entries to reflect edges\n",
    "A[0, [3, 9, 20, 14, 12, 11, 18, 21, 15, 22, 7, 4, 5, 2, 1]] = 1\n",
    "A[1, [0, 6, 2, 16, 24, 23, 25, 17, 10, 8]] = 1\n",
    "A[2, [1, 16, 30, 28, 27, 26, 7, 0, 4, 3]] = 1\n",
    "A[3, [19, 6, 2, 4, 7, 0, 15, 11, 18, 12, 14, 20, 9, 5]] = 1\n",
    "A[4, [13, 6, 2, 7, 15, 11, 0, 12, 14, 3]] = 1\n",
    "A[5, [19, 3, 0, 31]] = 1\n",
    "A[6, [1, 4, 3]] = 1\n",
    "A[7, [2, 26, 0, 3, 4]] = 1\n",
    "A[8, [32, 17, 10, 1, 13, 33]] = 1\n",
    "A[9, [3, 0, 31]] = 1\n",
    "A[10, [34, 17, 1, 13, 29, 8]] = 1\n",
    "A[11, [3, 0, 4, 15, 21, 18, 12, 14]] = 1\n",
    "A[12, [0, 11, 18, 20, 14, 3, 4]] = 1\n",
    "A[13, [8, 10, 4]] = 1\n",
    "A[14, [3, 4, 0, 11, 12]] = 1\n",
    "A[15, [4, 11, 3, 0]] = 1\n",
    "A[16, [23, 24, 2, 1]] = 1\n",
    "A[17, [1, 10, 8]] = 1\n",
    "A[18, [11, 12, 3, 0]] = 1\n",
    "A[19, [29, 3, 5]] = 1\n",
    "A[20, [3, 0, 12]] = 1\n",
    "A[21, [11, 0]] = 1\n",
    "A[22, [0]] = 1\n",
    "A[23, [24, 16, 1]] = 1\n",
    "A[24, [16, 1, 23]] = 1\n",
    "A[25, [1]] = 1\n",
    "A[26, [28, 27, 7, 2]] = 1\n",
    "A[27, [26, 2]] = 1\n",
    "A[28, [26, 2]] = 1\n",
    "A[29, [19, 10]] = 1\n",
    "A[30, [2]] = 1\n",
    "A[31, [35, 5, 9, 36]] = 1\n",
    "A[32, [34, 8, 33, 35]] = 1\n",
    "A[33, [32, 8, 35]] = 1\n",
    "A[34, [10, 32]] = 1\n",
    "A[35, [32, 33, 31, 36]] = 1\n",
    "A[36, [31, 35]] = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Python package NetworkX contains many tools to deal with graphs. After defining the adjacency matrix $A$, the following code defines the graph $G$ and obtains lists of the nodes and edges of the graph. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import networkx\n",
    "import networkx as nx\n",
    "\n",
    "# Define graph G using adjacency matrix A\n",
    "G = nx.Graph(A)\n",
    "\n",
    "# Print nodes and edges\n",
    "print(f'Nodes: {G.nodes()}')\n",
    "print(f'Edges: {G.edges()}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Degree centrality"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The _degree_ of a vertex is the number of edges incident to (i.e., that contain) the vertex. Since there are $N = 37$ nodes in the graph $G$ and no edges go from a vertex to the same vertex, each vertex can be connected to at most $N-1=36$ other vertices. It is common to divide the degree by the maximum possible degree to get a normalized degree value between 0 and 1 for each vertex; this helps mainly when comparing vertices in different graphs. This normalized degree value is called _degree centrality_.\n",
    "\n",
    "Ranking each conspirator by their degree centrality is the simplest way to determine influence. Those with the highest degree centrality have the most contacts and are potentially the most influential members of the network. The NetworkX method `degree_centrality(G)` returns a dictionary associating the degree centrality to each vertex in $G$. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Closeness centrality"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Closeness is another measure of influence in a graph $G$. Two vertices are distance $k$ apart if there is a path of $k$ edges linking the two vertices and no smaller path linking them. Two vertices that are not linked by a path are defined to be distance $\\infty$ away from each other. Denote the distance between vertices $u$ and $v$ by $d(u,v)$. The _closeness_ $c(v)$ of a vertex $v$ is defined to be the reciprocal of the sum of the distances from $v$ to each of the vertices: \n",
    "\n",
    "\\begin{equation*}\n",
    "c(v) = \\left[ \\sum_{u} d(u,v)\\right]^{-1}. \n",
    "\\end{equation*}\n",
    "\n",
    "It is common to replace the sum of the distances by the average distance. This amounts to multiplying the closeness by one less than the number of vertices to produce a number between 0 and 1. The _closeness centrality_ of a  vertex $v$ is\n",
    "\n",
    "\\begin{equation*}\n",
    "C(v) = (N-1)c(v).\n",
    "\\end{equation*}\n",
    "\n",
    "The closeness centrality can be used to determine influence in the graph; those conspirators with higher closeness centrality  are more closely related to the other conspirators and are able to spread information through the network quickly.  The NetworkX method `closeness_centrality(G)` returns a dictionary associating the closeness centrality to each vertex in $G$. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Betweenness centrality"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A third measure of influence, betweenness, was introduced by the sociologist Linton Freeman in 1977. The betweenness of a vertex $v$ is related to the number of shortest paths between all other pairs of vertices that pass through the vertex $v$. Specifically, the _betweenness_ $b(v)$ of a vertex $v$ is computed as \n",
    "\n",
    "\\begin{equation*}\n",
    "b(v) = \\sum \\frac{\\text{number of shortest paths between $s$ and $t$ that pass through $v$}}{\\text{number of shortest paths between $s$ and $t$}},\n",
    "\\end{equation*}\n",
    "\n",
    "where the sum is taken over all unordered pairs $\\{s,t\\}$ that don't include $v$. It is common to divide the betweenness $b(v)$ by the number of unordered pairs $\\binom{N-1}{2} = (N-1)(N-2)/2$ to produce a number between 0 and 1 to obtain the _betweenness centrality_ $B(v)$. Conspirators that have high betweenness centrality are influential in the sense that a high proportion of the closest relationships in the network are mediated through them. The NetworkX method `betweenness_centrality(G)` returns a dictionary associating the betweenness centrality to each vertex in $G$.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PageRank"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A fourth measure of influence was developed by the founders of Google. Their algorithm, PageRank, ranks webpages based on the link structure of the web, but it applies more generally to any digraph. Like a graph, a digraph (directed graph) has vertices but now each edge also carries a direction, so each edge has a start vertex and an end vertex. Directed edges are often called arcs, and are usually represented by arrows. Given a graph, we can make it into a digraph by replacing each edge with two directed edges, going in opposite directions, so PageRank can be applied to graphs as well. \n",
    "\n",
    "To describe PageRank, imagine that each vertex is a website and the directed edges from a given vertex point to websites to which our start vertex links. A user randomly clicks on links moving about the web, as follows. If they are at a webpage, then with probability $d$ they click on a link from that webpage. Each link from our webpage is equally likely to be chosen. With probability $1-d$ the user selects any of the webpages in the network; again, each website is equally likely to be chosen. \n",
    "\n",
    "We've been describing how an individual user behaves but we'd really like to apply these rules to many users distributed across the network. Imagine that we start with a population distribution  $R^0 \\in [0,1]^N$ (Note: This requires that the sum of the entries in $R^0$ is 1) on a network with $N$ webpages so that $R^0_i$ equals the proportion of users initially on webpage $i$ (the exponent 0 indicates that we are at the starting point for an evolving system $R^t$). Now increase $t$ by 1 and allow each user to move to a new webpage, as described above.\n",
    "The expected new population distribution is given by $R^{t+1} =  M R^t,$ \n",
    "where $M$ is a matrix with \n",
    "\n",
    "\\begin{equation*}\n",
    "M_{ij} = \\left\\{ \\begin{array}{ll} \\frac{d}{L_j} + \\frac{1-d}{N}  & \\text{if page $j$ links to page $i$} \\\\ \\frac{1-d}{N} & \\text{otherwise} \\end{array} \\right.\n",
    "\\end{equation*}\n",
    "\n",
    "and $L_j$ is the number of outgoing links on page $j$. The matrix $M$ is called the modified adjacency matrix of $G$ with damping factor $d$. It will be convenient later to know an equivalent way to compute this matrix: \n",
    "\n",
    "\\begin{equation*}\n",
    "M = d(K^{-1}A)^T + \\frac{1-d}{N}E,\n",
    "\\end{equation*}\n",
    "\n",
    "where $K$ is the matrix with the outdegrees (number of edges emerging from a vertex) along the diagonal and $E$ is the $N\\times N$ matrix filled with 1's. It turns out that if $d>0$, then this process converges, to a particular vector $R$, independent of the initial distribution of users on the network. This is a consequence of the Perron-Frobenius Theorem on eigenvalues of (stochastic) matrices. We won't go into the details of that theorem. However, note that since the steady state vector $R$ must satisfy the equation $R = MR$, we see immediately that $R$ is an eigenvector of $M$ corresponding to eigenvalue 1. The Perron-Frobenius Theorem implies that there is a unique eigenvector of $M$ with eigenvalue 1 with 1-norm equal to 1 whose entries are all positive. This is good since the $i^\\text{th}$ entry $R_i$ of the unit eigenvector $R$ should be interpreted as the proportion of users that end up on webpage $i$ in the long run. The entries of this eigenvector rank the importance of each of the vertices in the network; higher entries correspond to more important vertices. (Note: This eigenvector has been called the 25 billion dollar eigenvector, the value of Google when it went public in 2004. For more details on the Pagerank algorithm, see [Bryant and Leise's paper](https://www.rose-hulman.edu/~bryan/googleFinalVersionFixed.pdf).\n",
    "\n",
    "The NetworkX method `pagerank(G, d)` returns a dictionary associating the PageRank value to each vertex in $G$.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finding an eigenvector of a large matrix can be pretty difficult. So, how does NetworkX compute the PageRank? The Perron-Frobenius Theorem ensures that the matrix $M$ has a simple maximum eigenvalue (the number 1 appears as a root of the characteristic polynomial with multiplicity 1) and all other eigenvalues have 2-norm strictly less than 1. If we decompose a random vector $v$ into its projection onto the eigenspaces then $M$ acts by leaving the component in the 1-eigenspace alone but shrinks each other component (multiplies those components by $\\lambda$ with $\\| \\lambda \\|_2 < 1$). It follows that $M^tv$ converges to a vector whose normalization is $R$. In practice, this is the method used to compute the principal eigenvector $R$; we keep multiplying by $M$ (and normalizing, dividing by $\\| v \\|_1$ so that the vector remains a probability distribution) until the 2-norm of the difference between successive approximations is less than a given tolerance $\\epsilon$. Though this does not guarantee that the vector $v$ is within $\\epsilon$ of the limiting value $R$, in practice $v$ will tend to be close to $R$. You'll implement this method in the assignment to check that the NetworkX method `pagerank(G,d)` gives a reasonable value. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are many more measures of centrality and influence in graphs, but the degree centrality, closeness centrality, betweenness centrality, and PageRank measures will work for our purposes. Your goal in the assignment will be to produce four ranked lists of the most influential conspirators using these four measures. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Your Assignment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One of the learning goals of this project is to have you gain some experience with navigating documentation. You may need to use parts of NetworkX and NumPy that we did not explicitly cover in class. You should refer to the [NetworkX documentation](https://networkx.github.io/documentation/stable/) and the [NumPy documentation](https://numpy.org/devdocs/) throughout this assignment."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using the code given above that defined the adjacency matrix `A` and the graph $G$, print a statement to the screen counting the number of _undirected_ edges in `A`; that is, the edges $(s,t)$ and $(t,s)$ are considered the same and should only be counted once.\n",
    "\n",
    "_Hint._ Read the NetworkX documentation to find a method that might be helpful here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compute the degree centrality measures for the graph. Print the names and the degree centrality (just report 3 decimal places) of the five most influential terrorists to the screen. \n",
    "\n",
    "_Hint._ You might consider using the code\n",
    "\n",
    "```\n",
    "idx = np.array(measure_list).argsort()[::-1]\n",
    "``` \n",
    "\n",
    "which sets `idx` to an array of indices so that `measure_list[idx[0]]` returns the largest element of `measure_list`, `measure_list[idx[1]]` returns the next largest element of `measure_list`, etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compute the closeness centrality measures for the graph. Print the names and the closeness centrality of the five most influential terrorists to the screen. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part 4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Computing closeness centrality requires us to compute the distance between every pair of vertices. Compute the (shortest) distance between the vertex for Khalid Al-Mihdhar and the vertex for Zacarias Moussaoui. Print this distance and a shortest path (using names rather than vertex numbers) to the screen. Is there more than one such path? If so, print another to the screen. If not, print a statement to the screen that there is a unique path."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compute the betweenness centrality measures for the graph. Print the names and the betweenness centrality of the five most influential terrorists to the screen. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 6"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compute the PageRank measures for the graph (use the default value $d = 0.85$). Print the names and the PageRank of the five most influential terrorists to the screen. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 7"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_The note in Part 0 especially applies to this part!_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create the modified adjacency matrix $M$ for the graph (use the default value $d = 0.85$). Make a random vector $v$ in $[0,1]^{37}$, normalize $v$ with its 1-norm, and print it to the screen. \n",
    "\n",
    "Iteratively set $v = M v$ and normalize $v$ with its 1-norm. Stop when the 2-norm of the difference between successive $v$ vectors is less than $\\epsilon = 1 \\times 10^{-6}$. Print the number of iterations required and the final vector $v$ to the screen. \n",
    "\n",
    "Compute the 2-norm of the difference between the vector $v$ and the vector output by PageRank is less than $\\epsilon$. You should find this difference to be small. Print the difference to the screen. \n",
    "\n",
    "Be careful: we're using both 2-norms and 1-norms here. You need to use the correct norm in the correct places."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## When you're finished"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Make sure your notebook runs from top to bottom with no errors. One way to accomplish this is to click on __Kernel &#8594; Restart & Run All__. This will restart Python, and run your notebook from top to bottom."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- When you're ready, submit this notebook using the SM286D Submission Form linked on the [class website](https://www.usna.edu/users/math/uhan/sm286d/)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Grading"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Your work will be graded as follows (60 total points):\n",
    "\n",
    "- Part 1 (2 points)\n",
    "    - Print the correct number to the screen in a statement\n",
    "- Part 2 (7 points)\n",
    "    - Compute the degree centrality values (3), sort the list (2) and print to the screen (2)\n",
    "- Part 3 (7 points)\n",
    "    - Compute the closeness centrality values (3), sort the list (2) and print to the screen (2)\n",
    "- Part 4 (5 points)\n",
    "    - Print the correct distance and a path to the screen (2). Determine if the path is unique and print an appropriate statement to the screen (3).\n",
    "- Part 5 (7 points)\n",
    "    - Compute the betweenness centrality values (3), sort the list (2) and print to the screen (2) \n",
    "- Part 6 (7 points)\n",
    "    - Compute the PageRank values (3), sort the list (2) and print to the screen (2) \n",
    "- Part 7 (20 points)\n",
    "    - Make the matrix M (5), make random vector v (2), normalize v (1), iteratively multiply by M and normalize (4), stop at appropriate time (2), print values to screen (4). Verify your answer is close to the answer from Q6 (2). \n",
    "- All parts: Helpful comments throughout your code (5 points)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
